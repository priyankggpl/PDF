{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf74899-6def-4330-b039-83ef463b53bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.54063551 0.        ]\n",
      " [1.62108922 0.        ]\n",
      " [0.         0.0956039 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.array(np.random.randn(3,4))\n",
    "# print(x)\n",
    "\n",
    "\n",
    "\n",
    "class dense_layer:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = np.array(np.random.randn(n_inputs, n_neurons))\n",
    "        self.bias = np.zeros((1,n_neurons))\n",
    "    def forward(self, input):\n",
    "        self.output = np.dot(input, self.weights) + self.bias\n",
    "\n",
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "layer1_dense = dense_layer(4,3)\n",
    "layer2_dense = dense_layer(3,2)\n",
    "\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "layer1_dense.forward(x)\n",
    "# print(\"layer1_dense=\",layer1_dense.output)\n",
    "\n",
    "layer2_dense.forward(layer1_dense.output)\n",
    "# print(layer2_dense.output)\n",
    "\n",
    "activation1.forward(layer2_dense.output)\n",
    "print(activation1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5249f7f6-713a-452b-ad13-2ed7e5d9ffea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121.51041751873483, 3.353484652549023, 10.859062664920513]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "E = math.e\n",
    "layer_outputs =[4.8, 1.21, 2.385]\n",
    "\n",
    "exp_values = []\n",
    "\n",
    "for output in layer_outputs:\n",
    "    exp_values.append(E**output)\n",
    "print(exp_values)\n",
    "\n",
    "final_output = []\n",
    "for exp in exp_values:\n",
    "    final_output.append(exp/sum(exp_values))\n",
    "\n",
    "print(sum(final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40088b5c-9b30-42f5-b530-1bb99f34b5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121.51041752   3.35348465  10.85906266]\n",
      "[0.89528266 0.02470831 0.08000903]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "exp_outputs = [4.8, 1.21, 2.385]\n",
    "\n",
    "exp_values = np.exp(exp_outputs)\n",
    "print(exp_values)\n",
    "\n",
    "norm_values = exp_values/np.sum(exp_values)\n",
    "print(norm_values)\n",
    "\n",
    "print(np.sum(norm_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b94b7ac-bbbc-4bae-823c-c7adbf8297a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1_dense= [[-0.73405046 -1.62220044 -2.1208904 ]\n",
      " [-1.53223582 -1.49336239  1.5514885 ]\n",
      " [ 0.10727533  0.971751    0.96464284]]\n",
      "activation= [[0.         0.         0.        ]\n",
      " [0.         0.         1.5514885 ]\n",
      " [0.10727533 0.971751   0.96464284]]\n",
      "layer2_dense= [[ 0.          0.        ]\n",
      " [-0.93188402 -0.4525595 ]\n",
      " [-1.7562798   0.0956039 ]]\n",
      "softmax= [[0.5        0.5       ]\n",
      " [0.38241164 0.61758836]\n",
      " [0.13565188 0.86434812]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "x = np.array(np.random.randn(3,4))\n",
    "# print(x)\n",
    "\n",
    "\n",
    "\n",
    "class dense_layer:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = np.array(np.random.randn(n_inputs, n_neurons))\n",
    "        self.bias = np.zeros((1,n_neurons))\n",
    "    def forward(self, input):\n",
    "        self.output = np.dot(input, self.weights) + self.bias\n",
    "\n",
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class Activation_softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        norm_outputs = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = norm_outputs\n",
    "\n",
    "layer1_dense = dense_layer(4,3)\n",
    "layer2_dense = dense_layer(3,2)\n",
    "\n",
    "activation1 = Activation_ReLU()\n",
    "activation2 = Activation_softmax()\n",
    "layer1_dense.forward(x)\n",
    "print(\"layer1_dense=\",layer1_dense.output)\n",
    "\n",
    "activation1.forward(layer1_dense.output)\n",
    "print(\"activation=\",activation1.output)\n",
    "\n",
    "layer2_dense.forward(activation1.output)\n",
    "print(\"layer2_dense=\", layer2_dense.output)\n",
    "\n",
    "activation2.forward(layer2_dense.output)\n",
    "print(\"softmax=\", activation2.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af81204-c08c-4f2c-8e6f-1a94ca248e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
